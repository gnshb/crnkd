{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/ca/48/643d21747d52fa380f572f76c493779fc5b4bd03605247209d2dd0a6d9a9/keras-3.0.2-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.0.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.12/site-packages (from keras) (1.24.4)\n",
      "Collecting rich (from keras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/be/1520178fa01eabe014b16e72a952b9f900631142ccd03dc36cf93e30c1ce/rich-13.7.0-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting h5py (from keras)\n",
      "  Obtaining dependency information for h5py from https://files.pythonhosted.org/packages/da/15/b1effaca3ab3b3d74f9a294d2a07ba59e0c7ec3724b6eb440ed22eba5589/h5py-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached h5py-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting dm-tree (from keras)\n",
      "  Using cached dm-tree-0.1.8.tar.gz (35 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FDp7gBDhID6u",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfinplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, LSTM\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import finplot as fplt\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjtLfWPOI9sC"
   },
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "OeQGf8gdI4q2",
    "outputId": "f1cfedc6-8b6a-4954-99cf-ab4f09555916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "      <th>change %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-05</th>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>3.377857</td>\n",
       "      <td>2.863342</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>1.513354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>3.426786</td>\n",
       "      <td>3.470357</td>\n",
       "      <td>3.299643</td>\n",
       "      <td>3.322143</td>\n",
       "      <td>2.816113</td>\n",
       "      <td>1289310400</td>\n",
       "      <td>-0.104643</td>\n",
       "      <td>-3.053674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-07</th>\n",
       "      <td>3.278929</td>\n",
       "      <td>3.303571</td>\n",
       "      <td>3.223571</td>\n",
       "      <td>3.250357</td>\n",
       "      <td>2.755262</td>\n",
       "      <td>753048800</td>\n",
       "      <td>-0.028572</td>\n",
       "      <td>-0.871385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-08</th>\n",
       "      <td>3.229643</td>\n",
       "      <td>3.326786</td>\n",
       "      <td>3.215714</td>\n",
       "      <td>3.310714</td>\n",
       "      <td>2.806425</td>\n",
       "      <td>673500800</td>\n",
       "      <td>0.081071</td>\n",
       "      <td>2.510212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-09</th>\n",
       "      <td>3.328929</td>\n",
       "      <td>3.335000</td>\n",
       "      <td>3.219286</td>\n",
       "      <td>3.235000</td>\n",
       "      <td>2.742244</td>\n",
       "      <td>546845600</td>\n",
       "      <td>-0.093929</td>\n",
       "      <td>-2.821600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>194.139999</td>\n",
       "      <td>194.660004</td>\n",
       "      <td>193.169998</td>\n",
       "      <td>193.580002</td>\n",
       "      <td>193.580002</td>\n",
       "      <td>34049900</td>\n",
       "      <td>-0.559998</td>\n",
       "      <td>-0.288450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>193.899994</td>\n",
       "      <td>194.399994</td>\n",
       "      <td>191.729996</td>\n",
       "      <td>192.529999</td>\n",
       "      <td>192.529999</td>\n",
       "      <td>42628800</td>\n",
       "      <td>-1.369995</td>\n",
       "      <td>-0.706547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>187.149994</td>\n",
       "      <td>188.440002</td>\n",
       "      <td>183.889999</td>\n",
       "      <td>185.639999</td>\n",
       "      <td>185.639999</td>\n",
       "      <td>82488700</td>\n",
       "      <td>-1.509995</td>\n",
       "      <td>-0.806837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>184.220001</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>183.429993</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>58414500</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.016284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>182.149994</td>\n",
       "      <td>183.089996</td>\n",
       "      <td>180.880005</td>\n",
       "      <td>181.910004</td>\n",
       "      <td>181.910004</td>\n",
       "      <td>71919900</td>\n",
       "      <td>-0.239990</td>\n",
       "      <td>-0.131754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3776 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close   adj close  \\\n",
       "Date                                                                     \n",
       "2009-01-05    3.327500    3.435000    3.311071    3.377857    2.863342   \n",
       "2009-01-06    3.426786    3.470357    3.299643    3.322143    2.816113   \n",
       "2009-01-07    3.278929    3.303571    3.223571    3.250357    2.755262   \n",
       "2009-01-08    3.229643    3.326786    3.215714    3.310714    2.806425   \n",
       "2009-01-09    3.328929    3.335000    3.219286    3.235000    2.742244   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-12-28  194.139999  194.660004  193.169998  193.580002  193.580002   \n",
       "2023-12-29  193.899994  194.399994  191.729996  192.529999  192.529999   \n",
       "2024-01-02  187.149994  188.440002  183.889999  185.639999  185.639999   \n",
       "2024-01-03  184.220001  185.880005  183.429993  184.250000  184.250000   \n",
       "2024-01-04  182.149994  183.089996  180.880005  181.910004  181.910004   \n",
       "\n",
       "                volume    change  change %  \n",
       "Date                                        \n",
       "2009-01-05  1181608400  0.050357  1.513354  \n",
       "2009-01-06  1289310400 -0.104643 -3.053674  \n",
       "2009-01-07   753048800 -0.028572 -0.871385  \n",
       "2009-01-08   673500800  0.081071  2.510212  \n",
       "2009-01-09   546845600 -0.093929 -2.821600  \n",
       "...                ...       ...       ...  \n",
       "2023-12-28    34049900 -0.559998 -0.288450  \n",
       "2023-12-29    42628800 -1.369995 -0.706547  \n",
       "2024-01-02    82488700 -1.509995 -0.806837  \n",
       "2024-01-03    58414500  0.029999  0.016284  \n",
       "2024-01-04    71919900 -0.239990 -0.131754  \n",
       "\n",
       "[3776 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Company=\"Apple\" Period=10 years\n",
    "#Train: 2014-2021\n",
    "#Test: 2022-2024\n",
    "df = yf.download(\"AAPL\", period=\"15y\")\n",
    "df[\"Change\"] = df[\"Close\"] - df[\"Open\"]\n",
    "df[\"Change %\"] = (df[\"Change\"] / df[\"Open\"])*100\n",
    "train=df.iloc[:1500]\n",
    "test=df.iloc[1500:]\n",
    "names=[]\n",
    "for col in df.columns:\n",
    "    df.rename(columns={col:col.lower()},inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADX Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IsCReIXtda77"
   },
   "outputs": [],
   "source": [
    "def get_adx(high, low, close, lookback):\n",
    "    plus_dm = high.diff()\n",
    "    minus_dm = low.diff()\n",
    "    plus_dm[plus_dm < 0] = 0\n",
    "    minus_dm[minus_dm > 0] = 0\n",
    "\n",
    "    tr1 = pd.DataFrame(high - low)\n",
    "    tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "    tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "    frames = [tr1, tr2, tr3]\n",
    "    tr = pd.concat(frames, axis = 1, join = 'inner').max(axis = 1)\n",
    "    atr = tr.rolling(lookback).mean()\n",
    "\n",
    "    plus_di = 100 * (plus_dm.ewm(alpha = 1/lookback).mean() / atr)\n",
    "    minus_di = abs(100 * (minus_dm.ewm(alpha = 1/lookback).mean() / atr))\n",
    "    dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "    adx = ((dx.shift(1) * (lookback - 1)) + dx) / lookback\n",
    "    adx_smooth = adx.ewm(alpha = 1/lookback).mean()\n",
    "    return plus_di, minus_di, adx_smooth\n",
    "\n",
    "def NormToPi(ARR):\n",
    "    Arr = np.copy(ARR)\n",
    "    K1 = 10\n",
    "    while(Arr[len(Arr)-1]/K1 > 1): K1 *= 10\n",
    "    LX = Arr[len(Arr)-1]/K1\n",
    "    K2 = 1\n",
    "    while(LX * K2 < np.pi): K2 += 0.01\n",
    "    K2-= 0.01\n",
    "    return [ (Value/K1)*K2  for Value in Arr]\n",
    "\n",
    "def Operator(XS, YS, N = 100, Fr = \"4.1\"):\n",
    "    Xs = NormToPi(XS)\n",
    "    Ys = np.copy(YS)\n",
    "\n",
    "    def F(x, E=0.01):\n",
    "        while(E < 100):\n",
    "            Nm = 0\n",
    "            for Value in Xs:\n",
    "                if (abs(x - Value) < E):\n",
    "                    return Ys[Nm]\n",
    "                Nm += 1\n",
    "            E *= 10\n",
    "\n",
    "    def S(k, x, n = 100):\n",
    "        Sn = (((-1) ** k) * np.sin(n * x)) / (n * x - k * np.pi)\n",
    "        return Sn\n",
    "\n",
    "    def Ln(f, x, n = 100):\n",
    "        LN = 0\n",
    "        for k in range(1, n):\n",
    "            Sk = S(k,x,n)\n",
    "            xi = (k * np.pi) / n\n",
    "            LN +=  Sk * F(xi)\n",
    "        return LN\n",
    "\n",
    "    def Ah(f, x, n = 100):\n",
    "        AH = 0\n",
    "        for k in range(1, n):\n",
    "            AH += (((S(k-1, x, n) + S(k, x, n)) * f(k * (np.pi/n)))/2)\n",
    "        return AH\n",
    "\n",
    "    if(Fr == \"4.1\"):     return [Ln(F, x, n = N) for x in Xs]\n",
    "    if(Fr == \"5.38\"):   return [Ah(F, x, n = N) for x in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IUgHtKQfd5Jw"
   },
   "outputs": [],
   "source": [
    "df['plus_di'] = pd.DataFrame(get_adx(df['high'], df['low'], df['close'], 14)[0]).rename(columns = {0:'plus_di'})\n",
    "df['minus_di'] = pd.DataFrame(get_adx(df['high'], df['low'], df['close'], 14)[1]).rename(columns = {0:'minus_di'})\n",
    "df['adx'] = pd.DataFrame(get_adx(df['high'], df['low'], df['close'], 14)[2]).rename(columns = {0:'adx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vj2P2hu7z-Ps"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f2d823f85f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['close','plus_di','minus_di','adx']].plot(figsize=(12,10), color=['black','green','red','orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NEjz5Njc5IcA"
   },
   "outputs": [],
   "source": [
    "def HA(df, ohlc=['open', 'high', 'low', 'close']):\n",
    "    '''\n",
    "    Function to compute Heiken Ashi Candles (HA)\n",
    "\n",
    "    Args :\n",
    "        df : Pandas DataFrame which contains ['date', 'open', 'high', 'low', 'close', 'volume'] columns\n",
    "        ohlc: List defining OHLC Column names (default ['open', 'high', 'low', 'close'])\n",
    "\n",
    "    Returns :\n",
    "        df : Pandas DataFrame with new columns added for\n",
    "            Heiken Ashi Close (HA_$ohlc[3])\n",
    "            Heiken Ashi Open (HA_$ohlc[0])\n",
    "            Heiken Ashi High (HA_$ohlc[1])\n",
    "            Heiken Ashi Low (HA_$ohlc[2])'''\n",
    "\n",
    "\n",
    "    ha_open = 'HA_' + ohlc[0]\n",
    "    ha_high = 'HA_' + ohlc[1]\n",
    "    ha_low = 'HA_' + ohlc[2]\n",
    "    ha_close = 'HA_' + ohlc[3]\n",
    "\n",
    "    df[ha_close] = (df[ohlc[0]] + df[ohlc[1]] + df[ohlc[2]] + df[ohlc[3]]) / 4\n",
    "\n",
    "    df[ha_open] = 0.00\n",
    "    for i in range(0, len(df)):\n",
    "        if i == 0:\n",
    "            df[ha_open].iat[i] = (df[ohlc[0]].iat[i] + df[ohlc[3]].iat[i]) / 2\n",
    "        else:\n",
    "            df[ha_open].iat[i] = (df[ha_open].iat[i - 1] + df[ha_close].iat[i - 1]) / 2\n",
    "\n",
    "    df[ha_high]=df[[ha_open, ha_close, ohlc[1]]].max(axis=1)\n",
    "    df[ha_low]=df[[ha_open, ha_close, ohlc[2]]].min(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D0ytQRgH-TZS"
   },
   "outputs": [],
   "source": [
    "df=HA(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<finplot.CandlestickItem at 0x7f2d823e19f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fplt.candlestick_ochl(df[['HA_open', 'HA_close', 'HA_high', 'HA_low']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pajYZpITRIZb"
   },
   "source": [
    "# Creating Heiken-Ashi candle data\n",
    "This allows us to normalize and smoothen the curves, helping us reduce noise and have a clearer idea of the undelying trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sdI2M8IzRxh6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remember to use adj_close and not close'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''use ta to get candlestick data'''\n",
    "\n",
    "'''put graphs and visualize this data'''\n",
    "\n",
    "'''remember to use adj_close and not close'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['HA_close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .45 ))\n",
    "\n",
    "training_data_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00257675],\n",
       "       [0.00266323],\n",
       "       [0.00207064],\n",
       "       ...,\n",
       "       [0.94004891],\n",
       "       [0.93064432],\n",
       "       [0.91815184]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.00257675, 0.00266323, 0.00207064, 0.0021045 , 0.00214981,\n",
      "       0.00170822, 0.00145105, 0.00106209, 0.00035647, 0.00050702,\n",
      "       0.        , 0.0001867 , 0.00145929, 0.00142863, 0.00171326,\n",
      "       0.00191643, 0.00240194, 0.00241155, 0.00210633, 0.0018844 ,\n",
      "       0.00220701, 0.00255295, 0.00268932, 0.00335924, 0.00387496,\n",
      "       0.00358759, 0.00306318, 0.00321922, 0.00347227, 0.00285497,\n",
      "       0.00263852, 0.00219831, 0.00190682, 0.00168305, 0.0016135 ,\n",
      "       0.00196127, 0.00195578, 0.00164187, 0.0015833 , 0.0016286 ,\n",
      "       0.00197866, 0.00179791, 0.00110007, 0.00078387, 0.00122179,\n",
      "       0.00209627, 0.0026312 , 0.00293367, 0.00289157, 0.00317254,\n",
      "       0.00385757, 0.00396236, 0.00398249, 0.00457371, 0.00491279,\n",
      "       0.00484873, 0.0052592 , 0.00501896, 0.00440623, 0.0046991 ])]\n",
      "[0.004820359558327219]\n",
      "\n",
      "[array([0.00257675, 0.00266323, 0.00207064, 0.0021045 , 0.00214981,\n",
      "       0.00170822, 0.00145105, 0.00106209, 0.00035647, 0.00050702,\n",
      "       0.        , 0.0001867 , 0.00145929, 0.00142863, 0.00171326,\n",
      "       0.00191643, 0.00240194, 0.00241155, 0.00210633, 0.0018844 ,\n",
      "       0.00220701, 0.00255295, 0.00268932, 0.00335924, 0.00387496,\n",
      "       0.00358759, 0.00306318, 0.00321922, 0.00347227, 0.00285497,\n",
      "       0.00263852, 0.00219831, 0.00190682, 0.00168305, 0.0016135 ,\n",
      "       0.00196127, 0.00195578, 0.00164187, 0.0015833 , 0.0016286 ,\n",
      "       0.00197866, 0.00179791, 0.00110007, 0.00078387, 0.00122179,\n",
      "       0.00209627, 0.0026312 , 0.00293367, 0.00289157, 0.00317254,\n",
      "       0.00385757, 0.00396236, 0.00398249, 0.00457371, 0.00491279,\n",
      "       0.00484873, 0.0052592 , 0.00501896, 0.00440623, 0.0046991 ]), array([0.00266323, 0.00207064, 0.0021045 , 0.00214981, 0.00170822,\n",
      "       0.00145105, 0.00106209, 0.00035647, 0.00050702, 0.        ,\n",
      "       0.0001867 , 0.00145929, 0.00142863, 0.00171326, 0.00191643,\n",
      "       0.00240194, 0.00241155, 0.00210633, 0.0018844 , 0.00220701,\n",
      "       0.00255295, 0.00268932, 0.00335924, 0.00387496, 0.00358759,\n",
      "       0.00306318, 0.00321922, 0.00347227, 0.00285497, 0.00263852,\n",
      "       0.00219831, 0.00190682, 0.00168305, 0.0016135 , 0.00196127,\n",
      "       0.00195578, 0.00164187, 0.0015833 , 0.0016286 , 0.00197866,\n",
      "       0.00179791, 0.00110007, 0.00078387, 0.00122179, 0.00209627,\n",
      "       0.0026312 , 0.00293367, 0.00289157, 0.00317254, 0.00385757,\n",
      "       0.00396236, 0.00398249, 0.00457371, 0.00491279, 0.00484873,\n",
      "       0.0052592 , 0.00501896, 0.00440623, 0.0046991 , 0.00482036])]\n",
      "[0.004820359558327219, 0.005813807308651936]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m (x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_test)\n\u001b[1;32m      7\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(x_test, (x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m ))\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(predictions)\n\u001b[1;32m     10\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(((predictions \u001b[38;5;241m-\u001b[39m y_test) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title('Apple')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['HA_close'])\n",
    "plt.plot(valid[['HA_close', 'Predictions']])\n",
    "#plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
